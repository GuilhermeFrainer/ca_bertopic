{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "DATA_DIR = pathlib.Path(\"../data\")\n",
    "SAMPLE_SIZE = 10_000\n",
    "SEED = 2349479"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_parquet(DATA_DIR / \"processed/yelp_reviews_with_embeddings.parquet\")\n",
    "lf.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "from typing import Optional\n",
    "\n",
    "def sample_from_lf(\n",
    "    lf: pl.LazyFrame,\n",
    "    n: int,\n",
    "    seed: Optional[int] = None,\n",
    "    replace: bool = False\n",
    ") -> pl.LazyFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    lf_len = lf.select(\"index\").count().collect().item()\n",
    "    all_possible_rows = np.arange(lf_len)\n",
    "    sample_idxs = rng.choice(all_possible_rows, size=n, replace=replace)\n",
    "    return lf.filter(pl.col(\"index\").is_in(sample_idxs))\n",
    "\n",
    "sampled_lf = sample_from_lf(lf, n=SAMPLE_SIZE, seed=SEED)\n",
    "sampled_lf.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    sampled_lf\n",
    "    .drop([\n",
    "        # Removing because these columns follow weird distributions\n",
    "        # and don't seem necessarily that helpful\n",
    "        \"user_review_count\",\n",
    "        \"business_review_count\",\n",
    "        # Ignoring state for now to avoid\n",
    "        # making the data too dimensional\n",
    "        \"state\"\n",
    "    ]) \n",
    "    .collect()\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(col: str):\n",
    "    x = pl.col(col)\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "metadata_cols = [\n",
    "    \"date\",\n",
    "    \"stars\",\n",
    "    \"user_average_stars\",\n",
    "    \"yelping_since\",\n",
    "    \"business_stars\"\n",
    "]\n",
    "\n",
    "scaling_expressions = [\n",
    "    min_max_scaler(c)\n",
    "    for c in metadata_cols\n",
    "]\n",
    "\n",
    "df = df.with_columns(scaling_expressions)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = df.select(metadata_cols)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvlearn.cluster import MultiviewSpectralClustering\n",
    "\n",
    "N_CLUSTERS = 20\n",
    "\n",
    "embeddings = df[\"embedding\"].to_numpy()\n",
    "metadata = metadata_df.to_numpy()\n",
    "assert len(embeddings) == len(metadata)\n",
    "Xs = [embeddings, metadata]\n",
    "\n",
    "mvc = MultiviewSpectralClustering(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    random_state=SEED,\n",
    "    n_init=10\n",
    ")\n",
    "\n",
    "cluster_labels = mvc.fit_predict(Xs)\n",
    "df_results = df.with_columns(\n",
    "    pl.Series(name=\"topics\", values=cluster_labels)\n",
    ")\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"topics\"].null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "any(cluster_labels == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClusterMixin, BaseEstimator\n",
    "from typing import Optional\n",
    "\n",
    "class MVCWrapper(BaseEstimator, ClusterMixin):\n",
    "    metadata: np.ndarray\n",
    "    labels_: Optional[np.ndarray]\n",
    "\n",
    "    def __init__(self, model, metadata: np.ndarray):\n",
    "        self.model = model\n",
    "        self.metadata = metadata\n",
    "        self.labels_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        if not len(X) == len(self.metadata):\n",
    "            raise ValueError(\n",
    "                f\"Metadata and textual embeddings must have the same length. Found {len(X) and len(self.metadata)}\"\n",
    "            )\n",
    "        # Joins textual embeddings and metadata\n",
    "        # to prepare for Multi-View Clustering\n",
    "        Xs = [X, self.metadata]\n",
    "\n",
    "        self.model.fit(Xs)\n",
    "        self.labels_ = self.model.labels_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not len(X) == len(self.metadata):\n",
    "            raise ValueError(\n",
    "                f\"Metadata and textual embeddings must have the same length. Found {len(X) and len(self.metadata)}\"\n",
    "            )\n",
    "        Xs = [X, self.metadata]\n",
    "        return self.model.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vanilla_bertopic = BERTopic(\n",
    "    umap_model=UMAP(n_components=5, min_dist=0.0, metric=\"cosine\"),\n",
    "    hdbscan_model=HDBSCAN(min_cluster_size=15, prediction_data=True),\n",
    "    vectorizer_model=CountVectorizer(stop_words=\"english\"),\n",
    "    ctfidf_model=ClassTfidfTransformer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_topics, vanilla_probs = vanilla_bertopic.fit_transform(\n",
    "    df[\"text\"].to_list(), embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_bertopic.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc = MultiviewSpectralClustering(\n",
    "    n_clusters=len(vanilla_bertopic.get_topic_info()),\n",
    "    random_state=SEED,\n",
    "    n_init=10\n",
    ")\n",
    "\n",
    "mvc_wrapper = MVCWrapper(mvc, metadata=metadata)\n",
    "\n",
    "modded_bertopic = BERTopic(\n",
    "    umap_model=UMAP(n_components=5, min_dist=0.0, metric=\"cosine\"),\n",
    "    hdbscan_model=mvc_wrapper,\n",
    "    vectorizer_model=CountVectorizer(stop_words=\"english\"),\n",
    "    ctfidf_model=ClassTfidfTransformer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "modded_topics, modded_probs = modded_bertopic.fit_transform(\n",
    "    df[\"text\"].to_list(), embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "modded_bertopic.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "def coherence(m: BERTopic, docs: list[str], topics: list[int], coherence: str = \"c_v\") -> float:\n",
    "    \"\"\"\n",
    "    Computes coherence for topic model.\n",
    "    Code taken from https://github.com/MaartenGr/BERTopic/issues/90\n",
    "    \"\"\"\n",
    "    # Gets the same vectorizer instance used in the model\n",
    "    vectorizer = m.vectorizer_model\n",
    "    tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "    tokens = [tokenizer(doc) for doc in docs]\n",
    "    dictionary = Dictionary(tokens)\n",
    "    corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "\n",
    "    n_topics = len(set(topics))\n",
    "    topic_words = [\n",
    "        [word for word, _ in m.get_topic(topic)] # type: ignore\n",
    "        for topic in range(n_topics - 1) # Ignores noise topic number -1\n",
    "    ]\n",
    "\n",
    "    cm = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=tokens,\n",
    "        dictionary=dictionary,\n",
    "        corpus=corpus,\n",
    "        coherence=coherence\n",
    "    )\n",
    "    return cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import rbo\n",
    "\n",
    "\n",
    "def compute_bertopic_irbo(m: BERTopic, topk: int = 10, p: float = 0.9) -> float:\n",
    "    all_topics = m.get_topics()\n",
    "    \n",
    "    # Extracts topic words\n",
    "    topic_words = []\n",
    "    for topic_id, topic_list in all_topics.items():\n",
    "        # Skips outlier topic -1\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "        # Ignores score\n",
    "        words = [word for word, score in topic_list]\n",
    "        topic_words.append(words)\n",
    "    return compute_irbo(topic_words, topk=topk, p=p)\n",
    "\n",
    "\n",
    "def compute_irbo(topics: list[list[str]], topk: int = 10, p: float = 0.9) -> float:\n",
    "    \"\"\"\n",
    "    Calculates Inverted Rank-Biased Overlap (IRBO) for a list of topics.\n",
    "    \n",
    "    Args:\n",
    "        topics (list of list of str): A list where each element is a list of words (the topic).\n",
    "        topk (int): How many top words to consider from each topic.\n",
    "        p (float): The \"p\" parameter for RBO (usually 0.9). \n",
    "                   Higher p puts more weight on lower-ranked words.\n",
    "    \n",
    "    Returns:\n",
    "        float: The IRBO score (0.0 to 1.0). \n",
    "               0.0 means topics are identical (bad).\n",
    "               1.0 means topics are completely different (good).\n",
    "    \"\"\"\n",
    "    # 1. Truncate topics to top-k words\n",
    "    t_lists = [t[:topk] for t in topics]\n",
    "    \n",
    "    # 2. Generate all unique pairs of topics\n",
    "    pairs = list(itertools.combinations(t_lists, 2))\n",
    "    \n",
    "    if not pairs:\n",
    "        return 0.0\n",
    "    \n",
    "    # 3. Calculate RBO for each pair\n",
    "    rbo_scores = []\n",
    "    for t1, t2 in pairs:\n",
    "        # Extrapolated RBO used\n",
    "        score = rbo.RankingSimilarity(t1, t2).rbo_ext(p=p)\n",
    "        rbo_scores.append(score)\n",
    "\n",
    "    # 4. Average the RBO scores\n",
    "    avg_rbo = np.mean(rbo_scores)\n",
    "    \n",
    "    # 5. Invert to get IRBO (Diversity)\n",
    "    # 1 means diverse (good), 0 means redundant (bad)\n",
    "    return 1.0 - avg_rbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = [\n",
    "    {\n",
    "        \"model\": \"Vanilla\",\n",
    "        \"coherence\": coherence(vanilla_bertopic, df[\"text\"].to_list(), vanilla_topics),\n",
    "        \"exclusivity\": compute_bertopic_irbo(vanilla_bertopic)\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Multi-View\",\n",
    "        \"coherence\": coherence(modded_bertopic, df[\"text\"].to_list(), modded_topics),\n",
    "        \"exclusivity\": compute_bertopic_irbo(modded_bertopic)\n",
    "    }\n",
    "]\n",
    "pl.DataFrame(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca-bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
