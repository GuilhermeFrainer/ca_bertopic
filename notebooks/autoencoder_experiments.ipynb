{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pathlib\n",
    "\n",
    "DATA_PATH = \"../data/processed/embeddings_batches/batch_*.parquet\"\n",
    "DATA_DIR = pathlib.Path(\"../data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = lf.drop([\"text\", \"state\", \"embedding\"]).collect()\n",
    "embeddings_df = lf.select(\"embedding\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "embed_lf = pl.scan_parquet(\"../data/processed/yelp_reviews_with_embeddings.parquet\")\n",
    "embed_lf.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def reshape_metadata(df: pl.DataFrame, new_range: tuple = (-1, 1)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts metadata DataFrame to numpy array.\n",
    "    Scales variables as needed.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=new_range)\n",
    "    return scaler.fit_transform(df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SimpleFusionAE(nn.Module):\n",
    "    def __init__(self, text_dim: int, meta_dim: int, latent_dim=50):\n",
    "        super(SimpleFusionAE, self).__init__()\n",
    "\n",
    "        input_dim = text_dim + meta_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, text, metadata):\n",
    "        x = torch.cat((text, metadata), dim=1)\n",
    "\n",
    "        latent_representation = self.encoder(x)\n",
    "\n",
    "        reconstructed_x = self.decoder(latent_representation)\n",
    "\n",
    "        return reconstructed_x, latent_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_arr = reshape_metadata(metadata_df)\n",
    "embeddings_arr = embeddings_df[\"embedding\"].to_numpy()\n",
    "\n",
    "model = SimpleFusionAE(text_dim=embeddings_arr.shape[1], meta_dim=metadata_arr.shape[1]).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "x_embeddings = torch.tensor(embeddings_arr, dtype=torch.float32).cuda()\n",
    "x_metadata = torch.tensor(metadata_arr, dtype=torch.float32).cuda()\n",
    "\n",
    "dataset = TensorDataset(x_embeddings, x_metadata)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 20\n",
    "\n",
    "# Training the model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Training model\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_text, batch_meta in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        reconstructed_x, latent_representation = model(batch_text, batch_meta)\n",
    "\n",
    "        target = torch.cat((batch_text, batch_meta), dim=1)\n",
    "        loss = criterion(reconstructed_x, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss / len(dataloader):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass fused embeddings to the CPU to be stored\n",
    "# Doing this gradually as to avoid OOM\n",
    "\n",
    "inference_dataset = TensorDataset(x_embeddings, x_metadata)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "fused_embeddings_list = []\n",
    "with torch.no_grad():\n",
    "    for batch_text, batch_meta in inference_loader:\n",
    "        _, batch_latent = model(batch_text, batch_meta)\n",
    "        batch_latent_cpu = batch_latent.cpu().numpy()\n",
    "        fused_embeddings_list.append(batch_latent_cpu)\n",
    "\n",
    "fused_embeddings = np.vstack(fused_embeddings_list)\n",
    "fused_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame({\"fused_embeddings\": fused_embeddings}).write_parquet(\"../data/processed/fused_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_embeddings_lf = pl.scan_parquet(DATA_DIR / \"fused_embeddings.parquet\")\n",
    "fused_embeddings_lf.count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_parquet(DATA_DIR / \"yelp_reviews_with_embeddings.parquet\")\n",
    "lf.count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/fusion_autoencoder.weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from umap import UMAP\n",
    "from cuml.manifold import UMAP\n",
    "#from hdbscan import HDBSCAN\n",
    "from cuml.cluster import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vanilla_bertopic = BERTopic(\n",
    "    #umap_model=UMAP(n_components=5, min_dist=0.0, metric=\"cosine\", low_memory=True),\n",
    "    umap_model=UMAP(n_components=5, min_dist=0.0, metric=\"cosine\"),\n",
    "    hdbscan_model=HDBSCAN(min_cluster_size=15, prediction_data=True),\n",
    "    vectorizer_model=CountVectorizer(stop_words=\"english\"),\n",
    "    ctfidf_model=ClassTfidfTransformer()\n",
    ")\n",
    "\n",
    "modded_bertopic = BERTopic(\n",
    "    #umap_model=UMAP(n_components=5, min_dist=0.0, metric=\"cosine\", low_memory=True),\n",
    "    umap_model=UMAP(n_components=5, min_dist=0.0, metric=\"cosine\"),\n",
    "    hdbscan_model=HDBSCAN(min_cluster_size=15, prediction_data=True),\n",
    "    vectorizer_model=CountVectorizer(stop_words=\"english\"),\n",
    "    ctfidf_model=ClassTfidfTransformer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "max_rows = 1_000_000\n",
    "\n",
    "lf = pl.scan_parquet(DATA_DIR / \"yelp_reviews_with_embeddings.parquet\")\n",
    "\n",
    "encoder_lf = pl.read_parquet(DATA_DIR / \"fused_embeddings.parquet\")\n",
    "encoder_embeddings = encoder_lf.select(\"fused_embeddings\").to_series().to_numpy()\n",
    "encoder_embeddings = encoder_embeddings[:max_rows]\n",
    "total_rows = encoder_embeddings.shape[0]\n",
    "\n",
    "lf = lf.slice(0, total_rows)\n",
    "docs = lf.select(\"text\").collect().to_series().to_list()\n",
    "vanilla_embeddings = lf.select(\"embedding\").collect().to_series().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_topics, vanilla_probs = vanilla_bertopic.fit_transform(\n",
    "    docs, embeddings=vanilla_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "modded_topics, modded_probs = modded_bertopic.fit_transform(\n",
    "    docs, embeddings=encoder_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = pathlib.Path(\"../data/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_bertopic.get_topic_info().to_csv(OUTPUT_DIR / \"yelp_vanilla_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "modded_bertopic.get_topic_info().to_csv(OUTPUT_DIR / \"yelp_autoencoder_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_bertopic.get_document_info(docs).to_parquet(OUTPUT_DIR / \"yelp_vanilla_topic_assignments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "modded_bertopic.get_document_info(docs).to_parquet(OUTPUT_DIR / \"yelp_autoencoder_topic_assignments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import rbo\n",
    "\n",
    "\n",
    "def compute_bertopic_irbo(m: BERTopic, topk: int = 10, p: float = 0.9) -> float:\n",
    "    all_topics = m.get_topics()\n",
    "    \n",
    "    # Extracts topic words\n",
    "    topic_words = []\n",
    "    for topic_id, topic_list in all_topics.items():\n",
    "        # Skips outlier topic -1\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "        # Ignores score\n",
    "        words = [word for word, score in topic_list]\n",
    "        topic_words.append(words)\n",
    "    return compute_irbo(topic_words, topk=topk, p=p)\n",
    "\n",
    "\n",
    "def compute_irbo(topics: list[list[str]], topk: int = 10, p: float = 0.9) -> float:\n",
    "    \"\"\"\n",
    "    Calculates Inverted Rank-Biased Overlap (IRBO) for a list of topics.\n",
    "    \n",
    "    Args:\n",
    "        topics (list of list of str): A list where each element is a list of words (the topic).\n",
    "        topk (int): How many top words to consider from each topic.\n",
    "        p (float): The \"p\" parameter for RBO (usually 0.9). \n",
    "                   Higher p puts more weight on lower-ranked words.\n",
    "    \n",
    "    Returns:\n",
    "        float: The IRBO score (0.0 to 1.0). \n",
    "               0.0 means topics are identical (bad).\n",
    "               1.0 means topics are completely different (good).\n",
    "    \"\"\"\n",
    "    # 1. Truncate topics to top-k words\n",
    "    t_lists = [t[:topk] for t in topics]\n",
    "    \n",
    "    # 2. Generate all unique pairs of topics\n",
    "    pairs = list(itertools.combinations(t_lists, 2))\n",
    "    \n",
    "    if not pairs:\n",
    "        return 0.0\n",
    "\n",
    "    # 3. Calculate RBO for each pair\n",
    "    rbo_scores = []\n",
    "    for t1, t2 in pairs:\n",
    "        # Extrapolated RBO used\n",
    "        score = rbo.RankingSimilarity(t1, t2).rbo_ext(p=p)\n",
    "        rbo_scores.append(score)\n",
    "\n",
    "    # 4. Average the RBO scores\n",
    "    avg_rbo = np.mean(rbo_scores)\n",
    "    \n",
    "    # 5. Invert to get IRBO (Diversity)\n",
    "    # 1 means diverse (good), 0 means redundant (bad)\n",
    "    return 1.0 - avg_rbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_bertopic_irbo(vanilla_bertopic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_bertopic_irbo(modded_bertopic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "def coherence(m: BERTopic, docs: list[str], topics: list[int], coherence: str = \"c_v\") -> float:\n",
    "    \"\"\"\n",
    "    Computes coherence for topic model.\n",
    "    Code taken from https://github.com/MaartenGr/BERTopic/issues/90\n",
    "    \"\"\"\n",
    "    # Gets the same vectorizer instance used in the model\n",
    "    vectorizer = m.vectorizer_model\n",
    "    tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "    tokens = [tokenizer(doc) for doc in docs]\n",
    "    dictionary = Dictionary(tokens)\n",
    "    corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "\n",
    "    n_topics = len(set(topics))\n",
    "    topic_words = [\n",
    "        [word for word, _ in m.get_topic(topic)] # type: ignore\n",
    "        for topic in range(n_topics - 1) # Ignores noise topic number -1\n",
    "    ]\n",
    "\n",
    "    cm = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=tokens,\n",
    "        dictionary=dictionary,\n",
    "        corpus=corpus,\n",
    "        coherence=coherence\n",
    "    )\n",
    "    return cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence(vanilla_bertopic, docs, vanilla_topics, coherence=\"c_npmi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence(modded_bertopic, docs, modded_topics, coherence=\"c_npmi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca-bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
